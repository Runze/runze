{
    "collab_server" : "",
    "contents" : "# https://github.com/rstudio/blogdown/issues/51\n\nlibrary(magick)\nlibrary(pbapply)  # just so we have a progress bar, because this thing takes a while\n\nresize_n_compress <- function(file_in, file_out, xmax = 1920, quality = 0.7, cutoff = 10000) {\n  # xmax <- 1920  # y pixel max\n  # quality <- 0.7  # passed on to jpeg::writeJPEG()\n  # cutoff <- 100000  # files smaller than this will not be touched\n  # file_out <- \"test.jpg\"\n  if (file.size(file_in) < cutoff) {  # in this case, just copy file\n    if (!(file_in == file_out)) {\n      file.copy(from = file_in, to = file_out, overwrite = TRUE)\n    }\n  } else {# if larger than cutoff\n    # magick workflow\n    image_raw <- image_read(path = file_in)\n    if (image_info(image_raw)[\"width\"] > xmax) {  # only resize if smaller\n      image_resized <- image_scale(image = image_raw, geometry = as.character(xmax))\n    } else {\n      image_resized <- image_raw\n    }\n    image_write(image = image_resized, path = file_out, format = \"jpeg\", quality = quality)\n  }\n}\n\nfind_large_files <- function(dir_original, dir_scaled) {\n  # function to find all files which actually NEED to be rescaled\n  # otherwise we would end up rescaling files all the time, which is pretty bad\n  # dir_original <- \"static/img/\"\n  # dir_scaled <- \"public/img/\"\n  all_original <- list.files(path = dir_original, pattern = \"\\\\.(jpg|jpeg|png)$\", all.files = FALSE, no.. = TRUE, full.names = FALSE, recursive = TRUE)\n  all_scaled <- list.files(path = dir_scaled, pattern = \"\\\\.(jpg|jpeg|png)$\", all.files = FALSE, no.. = TRUE, full.names = FALSE, recursive = TRUE)\n  equal_sizes <- rank(x = file.size(paste0(dir_original, all_original))) == rank(file.size(paste0(dir_scaled, all_scaled[all_scaled %in% all_original])))\n  large_files <- all_original[equal_sizes]\n  return(large_files)\n}\n\nreduce_large_files <- function(dir_original, dir_scaled, xmax = 650, quality = .9, cutoff = 10000) {\n  large_files <- find_large_files(dir_original = dir_original, dir_scaled = dir_scaled)\n  pbapply::pboptions(type = \"txt\")  # other output will not go to terminal\n  pblapply(X = large_files, FUN = function(x) {\n    resize_n_compress(file_in = paste0(dir_original, x), file_out = paste0(dir_scaled, x), quality = quality, xmax = xmax, cutoff = cutoff)\n  })\n}\n\n# now let's do this\ninvisible(reduce_large_files(dir_original = \"static/post/\", dir_scaled = \"static/post/\"))\n",
    "created" : 1495351921143.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "341937707",
    "id" : "3E1B98C8",
    "lastKnownWriteTime" : 1495353689,
    "last_content_update" : 1495353689538,
    "path" : "~/Documents/Github/blog/helper_functions/resize_images.R",
    "project_path" : "helper_functions/resize_images.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}